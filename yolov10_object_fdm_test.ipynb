{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sulimanbadour1/3d_Printing_code_phd/blob/main/yolov10_object_fdm_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9vkEvFABbN"
      },
      "source": [
        "## FDM YOLOV10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "d20b3bd9-cfb4-4a11-8b69-106652e40b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun  7 19:58:49 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "21c570a4-bbde-4309-9903-947bbad0c7fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install YOLOv10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Currently, YOLOv10 does not have its own PyPI package. Therefore, we need to install the code from the source."
      ],
      "metadata": {
        "id": "eBrlDQHUo_M5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "f98f4980-e08e-47a9-deca-f52ec86deb42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/THU-MIG/yolov10.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** We will also install two additional packages: [`roboflow`](https://github.com/roboflow/roboflow-python) to download the dataset from [Roboflow Universe](https://universe.roboflow.com/), which we will use to train our model, and [`supervision`](https://github.com/roboflow/supervision), which we will use for visualizing the results."
      ],
      "metadata": {
        "id": "Szn2UQBxqxnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q supervision roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf6A7E9glExI",
        "outputId": "8a88838b-e2ba-4c89-991b-36bdc2945b0b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'opencv-python-headless' candidate (version 4.8.0.74 at https://files.pythonhosted.org/packages/76/02/f128517f3ade4bb5f71e2afd8461dba70e3f466ce745fa1fd1fade9ad1b7/opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/opencv-python-headless/) (requires-python:>=3.6))\n",
            "Reason for being yanked: deprecated, use 4.8.0.76\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download pre-trained weights"
      ],
      "metadata": {
        "id": "JMEtcxdshoEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** YOLOv10 provides weight files pre-trained on the COCO dataset in various sizes. Let's download them."
      ],
      "metadata": {
        "id": "CF1nAW3Dri83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {HOME}/weights\n",
        "!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10n.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10s.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10m.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10b.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10x.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10l.pt\n",
        "!ls -lh {HOME}/weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l67kw8xiYPX",
        "outputId": "29d457c6-1e8a-4ca6-eb8e-6b1ab20818bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 408M\n",
            "-rw-r--r-- 1 root root  80M May 26 15:53 yolov10b.pt\n",
            "-rw-r--r-- 1 root root 100M May 26 15:53 yolov10l.pt\n",
            "-rw-r--r-- 1 root root  64M May 26 15:54 yolov10m.pt\n",
            "-rw-r--r-- 1 root root  11M May 26 15:54 yolov10n.pt\n",
            "-rw-r--r-- 1 root root  32M May 26 15:54 yolov10s.pt\n",
            "-rw-r--r-- 1 root root 123M May 26 15:54 yolov10x.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download example data\n",
        "\n",
        "**NONE:** Let's download few example images. Feel free to use your images or videos."
      ],
      "metadata": {
        "id": "QGXXr46SlXrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p {HOME}/data\n",
        "# !wget -P {HOME}/data -q https://media.roboflow.com/notebooks/examples/dog.jpeg\n",
        "# !ls -lh {HOME}/data"
      ],
      "metadata": {
        "id": "HzN8FRtSlemo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with Pre-trained COCO Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** YOLOv10 is based on YOLOv8, and like YOLOv8, it can be used in both CLI and SDK modes."
      ],
      "metadata": {
        "id": "i4Z0cZapszEY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1qD4toTTw0"
      },
      "source": [
        "### 💻 CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FDbMt_M6PiXb"
      },
      "outputs": [],
      "source": [
        "# %cd {HOME}\n",
        "\n",
        "# !yolo task=detect mode=predict conf=0.25 save=True \\\n",
        "# model={HOME}/weights/yolov10n.pt \\\n",
        "# source={HOME}/data/dog.jpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NONE:** Let's display result."
      ],
      "metadata": {
        "id": "ZN9CdBZ2nYRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LyopYpK1TQrB"
      },
      "outputs": [],
      "source": [
        "# %cd {HOME}\n",
        "\n",
        "# from IPython.display import Image\n",
        "\n",
        "# Image(filename='runs/detect/predict/dog.jpeg', height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFMBYQtMVL-B"
      },
      "source": [
        "### 🐍 Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Rx9NWF-sVN6Y"
      },
      "outputs": [],
      "source": [
        "# from ultralytics import YOLOv10\n",
        "\n",
        "# model = YOLOv10(f'{HOME}/weights/yolov10n.pt')\n",
        "# results = model(source=f'{HOME}/data/dog.jpeg', conf=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kAi4PvrItTCf"
      },
      "outputs": [],
      "source": [
        "# results[0].boxes.xyxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HqT2M01K1LUb"
      },
      "outputs": [],
      "source": [
        "# results[0].boxes.conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gKIwJ5yw1PMb"
      },
      "outputs": [],
      "source": [
        "# results[0].boxes.cls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NONE:** Let's display result using `supervision`."
      ],
      "metadata": {
        "id": "O26ZKAsindq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import supervision as sv\n",
        "# from ultralytics import YOLOv10\n",
        "\n",
        "# model = YOLOv10(f'{HOME}/weights/yolov10n.pt')\n",
        "# image = cv2.imread(f'{HOME}/data/dog.jpeg')\n",
        "# results = model(image)[0]\n",
        "# detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "# bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
        "# label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "# annotated_image = bounding_box_annotator.annotate(\n",
        "#     scene=image, detections=detections)\n",
        "# annotated_image = label_annotator.annotate(\n",
        "#     scene=annotated_image, detections=detections)\n",
        "\n",
        "# sv.plot_image(annotated_image)"
      ],
      "metadata": {
        "id": "SaKTSzSWnG7s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset from Roboflow Universe"
      ],
      "metadata": {
        "id": "t8Epf5rhnpV_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSd93ZJzZZKt",
        "outputId": "2c91d294-fc48-48fc-f550-a537a104bcb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.196 is required but found version=8.1.34, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in fdm_suli-13 to yolov8::   1%|▏         | 1103/82305 [00:00<00:31, 2612.33it/s]"
          ]
        }
      ],
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "!pip install -q roboflow\n",
        "\n",
        "from google.colab import userdata\n",
        "from roboflow import Roboflow\n",
        "\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"CetHCLetqq83339qHnY6\")\n",
        "project = rf.workspace(\"fdmprint\").project(\"fdm_suli\")\n",
        "version = project.version(13)\n",
        "dataset = version.download(\"yolov8\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:**\n",
        "Make sure the last 4 lines of the data.yaml file have the following format:\n",
        "\n",
        "```\n",
        "test: ../test/images\n",
        "train: ../train/images\n",
        "val: ../valid/images\n",
        "```\n",
        "\n",
        "If using a dataset from Roboflow Universe, run the command below. 👇🏻"
      ],
      "metadata": {
        "id": "yvRoruMguOIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '$d' {dataset.location}/data.yaml\n",
        "!sed -i '$d' {dataset.location}/data.yaml\n",
        "!sed -i '$d' {dataset.location}/data.yaml\n",
        "!sed -i '$d' {dataset.location}/data.yaml\n",
        "!echo -e \"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\" >> {dataset.location}/data.yaml"
      ],
      "metadata": {
        "id": "2LLYQIS0tbC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2YkphuiaE7_"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=train epochs=10 batch=32 plots=True \\\n",
        "model={HOME}/weights/yolov10n.pt \\\n",
        "data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MScstfHhArr"
      },
      "outputs": [],
      "source": [
        "!ls {HOME}/runs/detect/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J35i8Ofhjxa"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-urTWUkhRmn"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/results.png', width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference with Custom Model"
      ],
      "metadata": {
        "id": "Sh6h0MOEy2WX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Let's start by loading our newly trained model."
      ],
      "metadata": {
        "id": "TNjsAO8m08ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLOv10\n",
        "\n",
        "model = YOLOv10(f'{HOME}/runs/detect/train/weights/best.pt')\n",
        "\n",
        "dataset = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f\"{dataset.location}/valid/images\",\n",
        "    annotations_directory_path=f\"{dataset.location}/valid/labels\",\n",
        "    data_yaml_path=f\"{dataset.location}/data.yaml\"\n",
        ")\n",
        "\n",
        "bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()"
      ],
      "metadata": {
        "id": "AY1ajwSzyXCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Let's randomly select an image from our validation set and visualize the results."
      ],
      "metadata": {
        "id": "ibNL8dwU1Jqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_image = random.choice(list(dataset.images.keys()))\n",
        "random_image = dataset.images[random_image]\n",
        "\n",
        "results = model(source=random_image, conf=0.25)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "annotated_image = bounding_box_annotator.annotate(\n",
        "    scene=random_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(\n",
        "    scene=annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image)"
      ],
      "metadata": {
        "id": "rDuvNsnH0OEV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}