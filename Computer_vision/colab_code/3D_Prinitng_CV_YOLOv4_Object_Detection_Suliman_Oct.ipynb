{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvN2-COJ9w4k"
      },
      "source": [
        "# YOLOv4 Tiny Dataset Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef1_2DwjF9Cy"
      },
      "source": [
        "Set up the Custom Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cdj4tmT5Cmdl",
        "outputId": "4ef79a62-7a9f-4245-d159-adb20f7177a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: '/content'\n",
            "d:\\Phd_Cz\\Archive_firstyear\\23_24 files\\CV_Code\\cv-suli\\colab_code\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jafer\\.virtualenvs\\cv-suli-EJkw_DUo\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\Phd_Cz\\Archive_firstyear\\23_24 files\\CV_Code\\cv-suli\\colab_code\\dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jafer\\.virtualenvs\\cv-suli-EJkw_DUo\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.24-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from roboflow)\n",
            "  Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
            "Collecting matplotlib (from roboflow)\n",
            "  Downloading matplotlib-3.8.3-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
            "Collecting numpy>=1.18.5 (from roboflow)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
            "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
            "Collecting Pillow>=7.1.2 (from roboflow)\n",
            "  Downloading pillow-10.2.0-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\jafer\\.virtualenvs\\cv-suli-ejkw_duo\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting requests (from roboflow)\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: six in c:\\users\\jafer\\.virtualenvs\\cv-suli-ejkw_duo\\lib\\site-packages (from roboflow) (1.16.0)\n",
            "Collecting urllib3>=1.26.6 (from roboflow)\n",
            "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting tqdm>=4.41.0 (from roboflow)\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 57.6/57.6 kB ? eta 0:00:00\n",
            "Collecting PyYAML>=5.3.1 (from roboflow)\n",
            "  Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\jafer\\.virtualenvs\\cv-suli-ejkw_duo\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->roboflow)\n",
            "  Using cached contourpy-1.2.0-cp312-cp312-win_amd64.whl.metadata (5.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->roboflow)\n",
            "  Downloading fonttools-4.50.0-cp312-cp312-win_amd64.whl.metadata (162 kB)\n",
            "     ---------------------------------------- 0.0/162.6 kB ? eta -:--:--\n",
            "     -------------------------------------- 162.6/162.6 kB 9.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jafer\\.virtualenvs\\cv-suli-ejkw_duo\\lib\\site-packages (from matplotlib->roboflow) (24.0)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->roboflow)\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->roboflow)\n",
            "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
            "Downloading roboflow-1.1.24-py3-none-any.whl (71 kB)\n",
            "   ---------------------------------------- 0.0/71.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 71.7/71.7 kB ? eta 0:00:00\n",
            "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "   ---------------------------------------- 0.0/158.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 158.3/158.3 kB 9.9 MB/s eta 0:00:00\n",
            "Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "   ---------------------------------------- 0.0/178.7 kB ? eta -:--:--\n",
            "   --------------------------------------- 178.7/178.7 kB 11.2 MB/s eta 0:00:00\n",
            "Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 58.8/58.8 kB ? eta 0:00:00\n",
            "Downloading opencv_python_headless-4.8.0.74-cp37-abi3-win_amd64.whl (38.0 MB)\n",
            "   ---------------------------------------- 0.0/38.0 MB ? eta -:--:--\n",
            "   - -------------------------------------- 1.0/38.0 MB 31.0 MB/s eta 0:00:02\n",
            "   -- ------------------------------------- 2.7/38.0 MB 34.1 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 4.6/38.0 MB 36.7 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 6.4/38.0 MB 37.0 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 8.2/38.0 MB 37.5 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 10.1/38.0 MB 38.1 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 12.0/38.0 MB 40.9 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 13.9/38.0 MB 40.9 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 15.7/38.0 MB 40.9 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 17.5/38.0 MB 40.9 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 19.3/38.0 MB 40.9 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 21.1/38.0 MB 38.6 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 22.9/38.0 MB 38.6 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 24.1/38.0 MB 36.4 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 25.5/38.0 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 27.4/38.0 MB 36.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 29.2/38.0 MB 36.3 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 31.0/38.0 MB 36.3 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 32.9/38.0 MB 34.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 35.6/38.0 MB 38.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  37.4/38.0 MB 38.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  37.9/38.0 MB 38.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 38.0/38.0 MB 32.7 MB/s eta 0:00:00\n",
            "Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
            "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 1.5/15.5 MB 48.6 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 3.3/15.5 MB 41.6 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 4.9/15.5 MB 39.3 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 4.9/15.5 MB 39.3 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 5.2/15.5 MB 23.6 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 7.9/15.5 MB 29.9 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 12.3/15.5 MB 38.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 14.2/15.5 MB 38.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  15.5/15.5 MB 54.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 15.5/15.5 MB 46.9 MB/s eta 0:00:00\n",
            "Downloading pillow-10.2.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
            "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
            "   ------------------------ --------------- 1.6/2.6 MB 50.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.6/2.6 MB 42.1 MB/s eta 0:00:00\n",
            "Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl (138 kB)\n",
            "   ---------------------------------------- 0.0/138.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 138.7/138.7 kB 8.0 MB/s eta 0:00:00\n",
            "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 78.3/78.3 kB 4.5 MB/s eta 0:00:00\n",
            "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "Downloading matplotlib-3.8.3-cp312-cp312-win_amd64.whl (7.6 MB)\n",
            "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
            "   ------- -------------------------------- 1.4/7.6 MB 44.5 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 3.2/7.6 MB 40.4 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 4.6/7.6 MB 32.6 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 5.7/7.6 MB 32.8 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 7.2/7.6 MB 33.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.6/7.6 MB 30.5 MB/s eta 0:00:00\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 54.5/54.5 kB ? eta 0:00:00\n",
            "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
            "Using cached contourpy-1.2.0-cp312-cp312-win_amd64.whl (187 kB)\n",
            "Downloading fonttools-4.50.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ----------------------------- ---------- 1.6/2.2 MB 33.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 34.3 MB/s eta 0:00:00\n",
            "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "   ---------------------------------------- 0.0/103.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 103.2/103.2 kB ? eta 0:00:00\n",
            "Installing collected packages: urllib3, tqdm, PyYAML, python-magic, python-dotenv, pyparsing, Pillow, numpy, kiwisolver, idna, fonttools, cycler, charset-normalizer, chardet, certifi, requests, opencv-python-headless, contourpy, requests-toolbelt, matplotlib, roboflow\n",
            "Successfully installed Pillow-10.2.0 PyYAML-6.0.1 certifi-2023.7.22 chardet-4.0.0 charset-normalizer-3.3.2 contourpy-1.2.0 cycler-0.10.0 fonttools-4.50.0 idna-2.10 kiwisolver-1.4.5 matplotlib-3.8.3 numpy-1.26.4 opencv-python-headless-4.8.0.74 pyparsing-3.1.2 python-dotenv-1.0.1 python-magic-0.4.27 requests-2.31.0 requests-toolbelt-1.0.0 roboflow-1.1.24 tqdm-4.66.2 urllib3-2.2.1\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in 3dPrinterFDM-Fault-Detection-3 to darknet:: 100%|██████████| 40731/40731 [00:02<00:00, 18357.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to 3dPrinterFDM-Fault-Detection-3 in darknet:: 100%|██████████| 522/522 [00:00<00:00, 2121.96it/s]\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "%mkdir dataset\n",
        "%cd ./dataset\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"F9fTMOhlrU7a3qfsYsNT\")\n",
        "project = rf.workspace(\"fault-detection-6hpnq\").project(\"3dprinterfdm-fault-detection\")\n",
        "dataset = project.version(3).download(\"darknet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKlSotFT9Zv-"
      },
      "source": [
        "Train a Custom Model on DarkNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDTvGt2zt7cm"
      },
      "source": [
        "## Configuring CUDA on Colab for YOLOv4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-bguKWgtxSx",
        "outputId": "7549b25e-baca-4ff7-c592-d3675966916e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n"
          ]
        }
      ],
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it. This can be helpful for debugging.\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6BRAVo182G5",
        "outputId": "058ec035-c833-48a2-e8a0-b02d33ae935e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Mar 19 14:20:56 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 551.76                 Driver Version: 551.76         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   50C    P8             10W /  100W |       0MiB /   6144MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#take a look at the kind of GPU we have\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5FkXxGmGK4Q",
        "outputId": "fc7d4828-e745-4f60-cecb-9d64d20c3d2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: compute_capability=75\n"
          ]
        }
      ],
      "source": [
        "# Change the number depending on what GPU is listed above, under NVIDIA-SMI > Name.\n",
        "# Tesla K80: 30\n",
        "# Tesla P100: 60\n",
        "# Tesla T4: 75\n",
        "%env compute_capability=75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16pvdFMa1FEe"
      },
      "source": [
        "## Installing Darknet for YOLOv4 on Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9uY-38P93oz",
        "outputId": "c3d3f164-0d2b-44c3-9684-d0f59cec7e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: '/content/'\n",
            "d:\\Phd_Cz\\Archive_firstyear\\23_24 files\\CV_Code\\cv-suli\\colab_code\\dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
            "UsageError: Line magic function `%rm` not found.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "%rm -rf darknet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQEktcfj9y9O",
        "outputId": "c7be4a8b-9448-401e-b1f8-c58b06fab224"
      },
      "outputs": [],
      "source": [
        "#we clone the fork of darknet maintained by roboflow\n",
        "#small changes have been made to configure darknet for training\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FS9Fd4-Yi8-"
      },
      "source": [
        "**IMPORTANT! If you're not using a Tesla P100 GPU**, then uncomment the sed command and replace the arch and code with that matching your GPU. A list can be found [here](http://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/). You can check with the command nvidia-smi (should be run above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyMBDkaL-Aep",
        "outputId": "dd503bbf-8196-41e3-8169-502597646b69"
      },
      "outputs": [],
      "source": [
        "#install environment from the Makefile. Changes to mitigate CUDA error.\n",
        "%cd /content/darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTONpkMcIvt2",
        "outputId": "f5f4dc71-5c09-48a0-9110-187b12e2086e"
      },
      "outputs": [],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGPDEjfAALrQ",
        "outputId": "739fb283-48a2-4874-b8a6-5a08a3cc0eeb"
      },
      "outputs": [],
      "source": [
        "#download the newly released yolov4-tiny weights\n",
        "%cd /content/darknet\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh-vu9eWSyYw"
      },
      "source": [
        "## Configure from Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFciBw3iSwqt",
        "outputId": "43dab0ac-c019-48c7-caa7-44f94520a842"
      },
      "outputs": [],
      "source": [
        "#Copy dataset\n",
        "%cp -r /content/dataset/3dPrinterFDM-Fault-Detection-3/. /content/darknet/\n",
        "#Set up training file directories for custom dataset\n",
        "%cd /content/darknet/\n",
        "%cp train/_darknet.labels data/obj.names\n",
        "%mkdir data/obj\n",
        "#copy image and labels\n",
        "%cp train/*.jpg data/obj/\n",
        "%cp valid/*.jpg data/obj/\n",
        "\n",
        "%cp train/*.txt data/obj/\n",
        "%cp valid/*.txt data/obj/\n",
        "\n",
        "with open('data/obj.data', 'w') as out:\n",
        "  out.write('classes = 3\\n')\n",
        "  out.write('train = data/train.txt\\n')\n",
        "  out.write('valid = data/valid.txt\\n')\n",
        "  out.write('names = data/obj.names\\n')\n",
        "  out.write('backup = backup/')\n",
        "\n",
        "#write train file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/train.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir('train') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')\n",
        "\n",
        "#write the valid file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/valid.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir('valid') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtRqO3QvjkP"
      },
      "source": [
        "## Write Custom Training Config for YOLOv4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_WJcqHhpeVr",
        "outputId": "86133a7b-dfc8-44f8-cbaa-dc23181a4658"
      },
      "outputs": [],
      "source": [
        "#we build config dynamically based on number of classes\n",
        "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
        "def file_len(fname):\n",
        "  with open(fname) as f:\n",
        "    for i, l in enumerate(f):\n",
        "      pass\n",
        "  return i + 1\n",
        "\n",
        "num_classes = file_len('train/_darknet.labels')\n",
        "max_batches = num_classes*2000\n",
        "steps1 = .8 * max_batches\n",
        "steps2 = .9 * max_batches\n",
        "steps_str = str(steps1)+','+str(steps2)\n",
        "num_filters = (num_classes + 5) * 3\n",
        "\n",
        "\n",
        "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
        "if os.path.exists('./cfg/custom-yolov4-tiny-detector.cfg'): os.remove('./cfg/custom-yolov4-tiny-detector.cfg')\n",
        "\n",
        "\n",
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03VuD4NHnxFx"
      },
      "outputs": [],
      "source": [
        "%%writetemplate ./cfg/custom-yolov4-tiny-detector.cfg\n",
        "[net]\n",
        "# Testing\n",
        "#batch=1\n",
        "#subdivisions=1\n",
        "# Training\n",
        "batch=64\n",
        "subdivisions=16\n",
        "width=416\n",
        "height=416\n",
        "channels=3\n",
        "momentum=0.9\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.00261\n",
        "burn_in=1000\n",
        "max_batches = {max_batches}\n",
        "policy=steps\n",
        "steps={steps_str}\n",
        "scales=.1,.1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "##################################\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes={num_classes}\n",
        "num=6\n",
        "jitter=.3\n",
        "scale_x_y = 1.05\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "[route]\n",
        "layers = -4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = -1, 23\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[yolo]\n",
        "mask = 1,2,3\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes={num_classes}\n",
        "num=6\n",
        "jitter=.3\n",
        "scale_x_y = 1.05\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2LAciMh4Cut",
        "outputId": "18ea2c4c-4259-4f59-95a7-d2de74263f17"
      },
      "outputs": [],
      "source": [
        "#here is the file that was just written.\n",
        "#you may consider adjusting certain things\n",
        "\n",
        "#like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
        "#if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
        "%cat cfg/custom-yolov4-tiny-detector.cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWrG9EGamSpH"
      },
      "source": [
        "## Train Custom YOLOv4 Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6miYFbvExqMd",
        "outputId": "131ba16b-c6dc-41cb-c908-6efdd2e0f11d"
      },
      "outputs": [],
      "source": [
        "!./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg yolov4-tiny.conv.29 -dont_show -map\n",
        "#If you get CUDA out of memory adjust subdivisions above!\n",
        "#adjust max batches down for shorter training above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBnwpBV5ZXxQ"
      },
      "source": [
        "## Infer Custom Objects with Saved YOLOv4 Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzoJQQw8Zdco"
      },
      "outputs": [],
      "source": [
        "#define utility function\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3dJB6NZv4kh",
        "outputId": "9293832f-9a7e-4250-81b7-c528ab09bde6"
      },
      "outputs": [],
      "source": [
        "#check if weigths have saved yet\n",
        "#backup houses the last weights for our detector\n",
        "#(file yolo-obj_last.weights will be saved to the build\\darknet\\x64\\backup\\ for each 100 iterations)\n",
        "#(file yolo-obj_xxxx.weights will be saved to the build\\darknet\\x64\\backup\\ for each 1000 iterations)\n",
        "#After training is complete - get result yolo-obj_final.weights from path build\\darknet\\x64\\bac\n",
        "!ls backup\n",
        "#if it is empty you haven't trained for long enough yet, you need to train for at least 100 iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gwfboR8Es-W",
        "outputId": "aca0d0a7-d007-4460-9188-15cf402b3d55"
      },
      "outputs": [],
      "source": [
        "#save final weights to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JcpT9chyral",
        "outputId": "cf866b1b-9feb-4576-8371-6b9be01efd3e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV7y6ZIP7aSx",
        "outputId": "41b4b997-eade-4ab6-d1a5-e3d8a0846029"
      },
      "outputs": [],
      "source": [
        "# Darknet Weights\n",
        "!cp /content/darknet/backup/custom-yolov4-tiny-detector_final.weights \"/content/drive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-_E3O5Mf4Mf"
      },
      "outputs": [],
      "source": [
        "#coco.names is hardcoded somewhere in the detector\n",
        "%cp data/obj.names data/coco.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NjKzw2TvZrOQ",
        "outputId": "c96478f6-f625-48d8-f318-934f02dcd4b8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#/test has images that we can test our detector on\n",
        "test_images = [f for f in os.listdir('test') if f.endswith('.jpg')]\n",
        "import random\n",
        "img_path = \"test/\" + random.choice(test_images);\n",
        "\n",
        "#test out our detector!\n",
        "!./darknet detect cfg/custom-yolov4-tiny-detector.cfg backup/custom-yolov4-tiny-detector_best.weights {img_path} -dont-show\n",
        "imShow('predictions.jpg')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
